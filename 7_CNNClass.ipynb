{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합성곱 신경망을 이용한 이미지 분류 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class ConvolutionNetwork:\n",
    "    \n",
    "    def __init__(self, n_kernels=10, units=10, batch_size=32, learning_rate=0.1):\n",
    "        self.n_kernels = n_kernels  \n",
    "        self.kernel_size = 3        \n",
    "        self.optimizer = None       \n",
    "        self.conv_w = None          \n",
    "        self.conv_b = None          \n",
    "        self.units = units          \n",
    "        self.batch_size = batch_size  \n",
    "        self.w1 = None             \n",
    "        self.b1 = None              \n",
    "        self.w2 = None             \n",
    "        self.b2 = None             \n",
    "        self.a1 = None              \n",
    "        self.losses = []           \n",
    "        self.val_losses = []        \n",
    "        self.lr = learning_rate   \n",
    "\n",
    "    def forpass(self, x):\n",
    "#         print('x.shape',x.shape)                     # (128,28,28,1)\n",
    "#         print('self.conv_w.shape',self.conv_w.shape) # (3,3,1,10)\n",
    "#         print('self.conv_w',self.conv_w)\n",
    "        c_out = tf.nn.conv2d(x, self.conv_w, strides=1, padding='SAME') + self.conv_b\n",
    "#         print('c_out.shape',c_out.shape)             # (128,28,28,10)\n",
    "#         print('c_out',c_out)\n",
    "        r_out = tf.nn.relu(c_out)\n",
    "#         print('r_out.shape',r_out.shape)             # (128,28,28,10)\n",
    "#         print('r_out',r_out)\n",
    "        p_out = tf.nn.max_pool2d(r_out, ksize=2, strides=2, padding='VALID')\n",
    "#         print('p_out.shape',p_out.shape)             # (128,14,14,10)\n",
    "#         print('p_out',p_out)\n",
    "        f_out = tf.reshape(p_out, [x.shape[0], -1])    # (128,1960)\n",
    "#         print('f_out.shape',f_out.shape)\n",
    "        z1 = tf.matmul(f_out, self.w1) + self.b1       # (128,1960)(1960,100)+(100,)=(128,100)\n",
    "                                                     \n",
    "        a1 = tf.nn.relu(z1)                          \n",
    "        z2 = tf.matmul(a1, self.w2) + self.b2          # (128,100)(100,10)+(10,)=(128,10)\n",
    "                                                     \n",
    "        return z2\n",
    "    \n",
    "    def init_weights(self, input_shape, n_classes):\n",
    "        g = tf.initializers.glorot_uniform()\n",
    "        self.conv_w = tf.Variable(g((3, 3, 1, self.n_kernels)))\n",
    "        self.conv_b = tf.Variable(np.zeros(self.n_kernels), dtype=float)\n",
    "        n_features = 14 * 14 * self.n_kernels\n",
    "        self.w1 = tf.Variable(g((n_features, self.units)))          \n",
    "        self.b1 = tf.Variable(np.zeros(self.units), dtype=float)    \n",
    "        self.w2 = tf.Variable(g((self.units, n_classes)))           \n",
    "        self.b2 = tf.Variable(np.zeros(n_classes), dtype=float)     \n",
    "        \n",
    "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
    "        self.init_weights(x.shape, y.shape[1])    \n",
    "        self.optimizer = tf.optimizers.SGD(learning_rate=self.lr)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print('에포크', i, end=' ')\n",
    "            \n",
    "            batch_losses = []\n",
    "            for x_batch, y_batch in self.gen_batch(x, y):\n",
    "                print('.', end='')\n",
    "                self.training(x_batch, y_batch) # x_batch.shape  (128, 28, 28, 1)\n",
    "                batch_losses.append(self.get_loss(x_batch, y_batch))\n",
    " \n",
    "            print()\n",
    "            self.losses.append(np.mean(batch_losses))\n",
    "            self.val_losses.append(self.get_loss(x_val, y_val))\n",
    "\n",
    "    def gen_batch(self, x, y):\n",
    "        bins = len(x) // self.batch_size                   \n",
    "        indexes = np.random.permutation(np.arange(len(x))) \n",
    "        x = x[indexes]\n",
    "        y = y[indexes]\n",
    "        for i in range(bins):\n",
    "            start = self.batch_size * i\n",
    "            end = self.batch_size * (i + 1)\n",
    "            yield x[start:end], y[start:end]   \n",
    "            \n",
    "    def training(self, x, y):\n",
    "        m = len(x)                    \n",
    "        with tf.GradientTape() as tape:\n",
    "            z = self.forpass(x)       \n",
    "            loss = tf.nn.softmax_cross_entropy_with_logits(y, z)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "        weights_list = [self.conv_w, self.conv_b,\n",
    "                        self.w1, self.b1, self.w2, self.b2]\n",
    "        grads = tape.gradient(loss, weights_list)\n",
    "        self.optimizer.apply_gradients(zip(grads, weights_list))\n",
    "   \n",
    "    def predict(self, x):\n",
    "        z = self.forpass(x)                 \n",
    "        return np.argmax(z.numpy(), axis=1) \n",
    "\n",
    "    def score(self, x, y):\n",
    "        return np.mean(self.predict(x) == np.argmax(y, axis=1))\n",
    "\n",
    "    def get_loss(self, x, y):\n",
    "        z = self.forpass(x)                 \n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, z))\n",
    "        return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_all.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, \n",
    "                                                  test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_val_encoded = tf.keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_val = x_val.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_val = x_val / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = ConvolutionNetwork(n_kernels=10, units=100, batch_size=128, learning_rate=0.01)\n",
    "cn.fit(x_train, y_train_encoded, \n",
    "       x_val=x_val, y_val=y_val_encoded, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cn.losses)\n",
    "plt.plot(cn.val_losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn.score(x_val, y_val_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
